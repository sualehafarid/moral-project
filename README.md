# Multicultural Morality Project

This project investigates how Large Language Models (LLMs) perform on moral reasoning tasks across multiple languages. The research explores:

- **RQ1: Prompting LLMs** - Zero-shot performance of different LLMs for moral reasoning tasks
- **RQ2: Reasoning Probing** - Analysis of reasoning patterns in moral decision-making
- **RQ3: Model Values** - Investigation of value alignment across different models and languages

## Datasets

### Translated Datasets

You can download the translated datasets used in this research from our Hugging Face repository:

**[Download Translated Datasets](https://huggingface.co/moralproj/datasets)**

The datasets include moral reasoning scenarios translated into multiple languages including:
- Chinese (中文)
- English
- German (Deutsch)
- Hindi (हिन्दी)
- Spanish (Español)
- Urdu (اردو)

## Citation

If you use this research or datasets in your work, please cite:

```
@misc{farid2025modelmoralsuncoveringcrosslinguistic,
      title={One Model, Many Morals: Uncovering Cross-Linguistic Misalignments in Computational Moral Reasoning}, 
      author={Sualeha Farid and Jayden Lin and Zean Chen and Shivani Kumar and David Jurgens},
      year={2025},
      eprint={2509.21443},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2509.21443}, 
}
```

## License

This project is for research purposes. Please refer to the individual dataset licenses for usage restrictions.
